{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[필사 원본 링크](https://www.kaggle.com/code/sasha18/recommend-books-using-count-tfidf-on-titles) <br>\n",
    "[코사인 유사도 관련 영상](https://www.youtube.com/watch?v=e9U0QAFbfLI&ab_channel=StatQuestwithJoshStarmer)\n",
    "## 이 노트북을 선택한 이유\n",
    "* 제목에 TFidf 가 눈에 가장 먼저 들어왔다.\n",
    "* 관련 기억이 전혀 나지 않음\n",
    "* 복습하기에 좋은 노트북이라고 판단"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "3   4     2657          2657  3275794          487   61120081  9.780061e+12   \n",
       "4   5     4671          4671   245494         1356  743273567  9.780743e+12   \n",
       "\n",
       "                       authors  original_publication_year  \\\n",
       "0              Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2              Stephenie Meyer                     2005.0   \n",
       "3                   Harper Lee                     1960.0   \n",
       "4          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "PATH = '/Users/jahyeon_gu/Downloads'\n",
    "\n",
    "data = pd.read_csv(f\"{PATH}/books.csv\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 살펴보기 (프리스타일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         10000 non-null  int64  \n",
      " 1   book_id                    10000 non-null  int64  \n",
      " 2   best_book_id               10000 non-null  int64  \n",
      " 3   work_id                    10000 non-null  int64  \n",
      " 4   books_count                10000 non-null  int64  \n",
      " 5   isbn                       9300 non-null   object \n",
      " 6   isbn13                     9415 non-null   float64\n",
      " 7   authors                    10000 non-null  object \n",
      " 8   original_publication_year  9979 non-null   float64\n",
      " 9   original_title             9415 non-null   object \n",
      " 10  title                      10000 non-null  object \n",
      " 11  language_code              8916 non-null   object \n",
      " 12  average_rating             10000 non-null  float64\n",
      " 13  ratings_count              10000 non-null  int64  \n",
      " 14  work_ratings_count         10000 non-null  int64  \n",
      " 15  work_text_reviews_count    10000 non-null  int64  \n",
      " 16  ratings_1                  10000 non-null  int64  \n",
      " 17  ratings_2                  10000 non-null  int64  \n",
      " 18  ratings_3                  10000 non-null  int64  \n",
      " 19  ratings_4                  10000 non-null  int64  \n",
      " 20  ratings_5                  10000 non-null  int64  \n",
      " 21  image_url                  10000 non-null  object \n",
      " 22  small_image_url            10000 non-null  object \n",
      "dtypes: float64(3), int64(13), object(7)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치형 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9.415000e+03</td>\n",
       "      <td>9979.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>5.264697e+06</td>\n",
       "      <td>5.471214e+06</td>\n",
       "      <td>8.646183e+06</td>\n",
       "      <td>75.712700</td>\n",
       "      <td>9.755044e+12</td>\n",
       "      <td>1981.987674</td>\n",
       "      <td>4.002191</td>\n",
       "      <td>5.400124e+04</td>\n",
       "      <td>5.968732e+04</td>\n",
       "      <td>2919.955300</td>\n",
       "      <td>1345.040600</td>\n",
       "      <td>3110.885000</td>\n",
       "      <td>11475.893800</td>\n",
       "      <td>1.996570e+04</td>\n",
       "      <td>2.378981e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.575462e+06</td>\n",
       "      <td>7.827330e+06</td>\n",
       "      <td>1.175106e+07</td>\n",
       "      <td>170.470728</td>\n",
       "      <td>4.428619e+11</td>\n",
       "      <td>152.576665</td>\n",
       "      <td>0.254427</td>\n",
       "      <td>1.573700e+05</td>\n",
       "      <td>1.678038e+05</td>\n",
       "      <td>6124.378132</td>\n",
       "      <td>6635.626263</td>\n",
       "      <td>9717.123578</td>\n",
       "      <td>28546.449183</td>\n",
       "      <td>5.144736e+04</td>\n",
       "      <td>7.976889e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.951703e+08</td>\n",
       "      <td>-1750.000000</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>2.716000e+03</td>\n",
       "      <td>5.510000e+03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.540000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>4.627575e+04</td>\n",
       "      <td>4.791175e+04</td>\n",
       "      <td>1.008841e+06</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>1.356875e+04</td>\n",
       "      <td>1.543875e+04</td>\n",
       "      <td>694.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>3112.000000</td>\n",
       "      <td>5.405750e+03</td>\n",
       "      <td>5.334000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>3.949655e+05</td>\n",
       "      <td>4.251235e+05</td>\n",
       "      <td>2.719524e+06</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>9.780452e+12</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.115550e+04</td>\n",
       "      <td>2.383250e+04</td>\n",
       "      <td>1402.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>4894.000000</td>\n",
       "      <td>8.269500e+03</td>\n",
       "      <td>8.836000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>9.382225e+06</td>\n",
       "      <td>9.636112e+06</td>\n",
       "      <td>1.451775e+07</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>9.780831e+12</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>4.105350e+04</td>\n",
       "      <td>4.591500e+04</td>\n",
       "      <td>2744.250000</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>2353.250000</td>\n",
       "      <td>9287.000000</td>\n",
       "      <td>1.602350e+04</td>\n",
       "      <td>1.730450e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>3.328864e+07</td>\n",
       "      <td>3.553423e+07</td>\n",
       "      <td>5.639960e+07</td>\n",
       "      <td>3455.000000</td>\n",
       "      <td>9.790008e+12</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.820000</td>\n",
       "      <td>4.780653e+06</td>\n",
       "      <td>4.942365e+06</td>\n",
       "      <td>155254.000000</td>\n",
       "      <td>456191.000000</td>\n",
       "      <td>436802.000000</td>\n",
       "      <td>793319.000000</td>\n",
       "      <td>1.481305e+06</td>\n",
       "      <td>3.011543e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       book_id  best_book_id       work_id   books_count  \\\n",
       "count  10000.00000  1.000000e+04  1.000000e+04  1.000000e+04  10000.000000   \n",
       "mean    5000.50000  5.264697e+06  5.471214e+06  8.646183e+06     75.712700   \n",
       "std     2886.89568  7.575462e+06  7.827330e+06  1.175106e+07    170.470728   \n",
       "min        1.00000  1.000000e+00  1.000000e+00  8.700000e+01      1.000000   \n",
       "25%     2500.75000  4.627575e+04  4.791175e+04  1.008841e+06     23.000000   \n",
       "50%     5000.50000  3.949655e+05  4.251235e+05  2.719524e+06     40.000000   \n",
       "75%     7500.25000  9.382225e+06  9.636112e+06  1.451775e+07     67.000000   \n",
       "max    10000.00000  3.328864e+07  3.553423e+07  5.639960e+07   3455.000000   \n",
       "\n",
       "             isbn13  original_publication_year  average_rating  ratings_count  \\\n",
       "count  9.415000e+03                9979.000000    10000.000000   1.000000e+04   \n",
       "mean   9.755044e+12                1981.987674        4.002191   5.400124e+04   \n",
       "std    4.428619e+11                 152.576665        0.254427   1.573700e+05   \n",
       "min    1.951703e+08               -1750.000000        2.470000   2.716000e+03   \n",
       "25%    9.780316e+12                1990.000000        3.850000   1.356875e+04   \n",
       "50%    9.780452e+12                2004.000000        4.020000   2.115550e+04   \n",
       "75%    9.780831e+12                2011.000000        4.180000   4.105350e+04   \n",
       "max    9.790008e+12                2017.000000        4.820000   4.780653e+06   \n",
       "\n",
       "       work_ratings_count  work_text_reviews_count      ratings_1  \\\n",
       "count        1.000000e+04             10000.000000   10000.000000   \n",
       "mean         5.968732e+04              2919.955300    1345.040600   \n",
       "std          1.678038e+05              6124.378132    6635.626263   \n",
       "min          5.510000e+03                 3.000000      11.000000   \n",
       "25%          1.543875e+04               694.000000     196.000000   \n",
       "50%          2.383250e+04              1402.000000     391.000000   \n",
       "75%          4.591500e+04              2744.250000     885.000000   \n",
       "max          4.942365e+06            155254.000000  456191.000000   \n",
       "\n",
       "           ratings_2      ratings_3     ratings_4     ratings_5  \n",
       "count   10000.000000   10000.000000  1.000000e+04  1.000000e+04  \n",
       "mean     3110.885000   11475.893800  1.996570e+04  2.378981e+04  \n",
       "std      9717.123578   28546.449183  5.144736e+04  7.976889e+04  \n",
       "min        30.000000     323.000000  7.500000e+02  7.540000e+02  \n",
       "25%       656.000000    3112.000000  5.405750e+03  5.334000e+03  \n",
       "50%      1163.000000    4894.000000  8.269500e+03  8.836000e+03  \n",
       "75%      2353.250000    9287.000000  1.602350e+04  1.730450e+04  \n",
       "max    436802.000000  793319.000000  1.481305e+06  3.011543e+06  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>language_code</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9300</td>\n",
       "      <td>10000</td>\n",
       "      <td>9415</td>\n",
       "      <td>10000</td>\n",
       "      <td>8916</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9300</td>\n",
       "      <td>4664</td>\n",
       "      <td>9274</td>\n",
       "      <td>9964</td>\n",
       "      <td>25</td>\n",
       "      <td>6669</td>\n",
       "      <td>6669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>439023483</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td></td>\n",
       "      <td>Selected Poems</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6341</td>\n",
       "      <td>3332</td>\n",
       "      <td>3332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn       authors original_title           title language_code  \\\n",
       "count        9300         10000           9415           10000          8916   \n",
       "unique       9300          4664           9274            9964            25   \n",
       "top     439023483  Stephen King                 Selected Poems           eng   \n",
       "freq            1            60              5               4          6341   \n",
       "\n",
       "                                                image_url  \\\n",
       "count                                               10000   \n",
       "unique                                               6669   \n",
       "top     https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "freq                                                 3332   \n",
       "\n",
       "                                          small_image_url  \n",
       "count                                               10000  \n",
       "unique                                               6669  \n",
       "top     https://s.gr-assets.com/assets/nophoto/book/50...  \n",
       "freq                                                 3332  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41865</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2657</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4671</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title\n",
       "0  2767052            The Hunger Games (The Hunger Games, #1)\n",
       "1        3  Harry Potter and the Sorcerer's Stone (Harry P...\n",
       "2    41865                            Twilight (Twilight, #1)\n",
       "3     2657                              To Kill a Mockingbird\n",
       "4     4671                                   The Great Gatsby"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 책의 아이디와 제목만 추출\n",
    "books_title = data[['book_id', 'title']]\n",
    "\n",
    "# 책의 개수 : 10,000개 \n",
    "print(books_title.shape)\n",
    "books_title.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "* `analyzer` : 단어, 문자 단위의 벡터화 방법 정의\n",
    "* `ngram_range` : BOW 단위 수 (1, 3) 이라면 1개~3개까지 토큰을 묶어서 벡터화\n",
    "* `max_df` : 어휘를 작성할 때 문서 빈도가 주어진 임계값보다 높은 용어(말뭉치 관련 불용어)는 제외 (기본값=1.0)\n",
    "  * 너무 많이 등장하는 단어를 제외하는 효과\n",
    "  * `max_df=0.9` : 문서의 90% 이상에 나타나는 단어 제외\n",
    "  * `max_df=10` : 문서에 10개 이상 나타나는 단어 제외\n",
    "* `min_df` : 어휘를 작성할 때 문서 빈도가 주어진 임계값보다 낮은 용어는 제외합니다. 컷오프라고도 합니다.(기본값=1.0)\n",
    "  * 너무 적게 등장하는 단어를 제외하는 효과\n",
    "  * `min_df=0.01` : 문서의 1% 미만으로 나타나는 단어 제외\n",
    "  * `min_df=10` : 문서에 10개 미만으로 나타나는 단어 제외\n",
    "* `stop_words` : 불용어 정의\n",
    "* `max_features` : 어휘의 양을 제한\n",
    "  * `max_features=10` : 10개의 단어만 추출\n",
    "  * 단어를 너무 많이 사용해서 dtm 이 커지는 것을 방지하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 261)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer='word', ngram_range=(1, 2), stop_words='english', min_df=0.002)\n",
    "\n",
    "# 책 제목으로 BOW 생성\n",
    "vect.fit(books_title[\"title\"])\n",
    "\n",
    "# 단어 문서 행렬\n",
    "title_matrix = vect.transform(books_title[\"title\"])\n",
    "\n",
    "# 10,000개의 책 제목에 대하여 261개의 단어\n",
    "title_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['01', '10', '11', '12', '13', '14', '15', '16', '39', 'adventures',\n",
       "       'alex', 'alex cross', 'america', 'american', 'angel', 'angels',\n",
       "       'anita', 'anita blake', 'apprentice', 'art', 'bad', 'batman',\n",
       "       'beautiful', 'beauty', 'best', 'big', 'black', 'blake',\n",
       "       'blake vampire', 'blood', 'blue', 'body', 'bone', 'bones', 'book',\n",
       "       'books', 'born', 'bosch', 'bosch universe', 'boy', 'boys',\n",
       "       'broken', 'brothers', 'case', 'cat', 'child', 'children',\n",
       "       'chronicles', 'circle', 'city', 'club', 'complete', 'confessions',\n",
       "       'cross', 'cycle', 'dance', 'dark', 'dark hunter', 'darkest',\n",
       "       'darkness', 'daughter', 'davenport', 'dawn', 'day', 'days', 'dead',\n",
       "       'death', 'death death', 'detective', 'devil', 'diaries', 'diary',\n",
       "       'die', 'discworld', 'dog', 'don', 'dragon', 'dream', 'dreams',\n",
       "       'earth', 'empire', 'end', 'fall', 'fallen', 'family', 'fear',\n",
       "       'files', 'food', 'forever', 'forgotten', 'forgotten realms',\n",
       "       'game', 'garden', 'girl', 'girls', 'glass', 'god', 'gods',\n",
       "       'golden', 'gone', 'good', 'grave', 'great', 'green', 'guide',\n",
       "       'hard', 'harry', 'harry bosch', 'harry potter', 'heart', 'heaven',\n",
       "       'hercule', 'hercule poirot', 'hidden', 'high', 'history', 'home',\n",
       "       'house', 'human', 'hunter', 'ice', 'immortals', 'inside', 'island',\n",
       "       'jack', 'jack reacher', 'john', 'journey', 'just', 'kay',\n",
       "       'kay scarpetta', 'key', 'king', 'kinsey', 'kinsey millhone',\n",
       "       'kiss', 'knight', 'know', 'lady', 'left', 'legacy', 'legend',\n",
       "       'life', 'light', 'like', 'little', 'lives', 'living', 'long',\n",
       "       'lord', 'lost', 'love', 'lucas', 'lucas davenport', 'magic',\n",
       "       'magician', 'man', 'memoir', 'men', 'mercy', 'midnight',\n",
       "       'millhone', 'mind', 'miss', 'moon', 'mr', 'murder', 'new', 'night',\n",
       "       'novel', 'novels', 'old', 'people', 'perfect', 'plum', 'poems',\n",
       "       'poirot', 'potter', 'power', 'pretty', 'prey', 'prey lucas',\n",
       "       'prince', 'princess', 'queen', 'reacher', 'realms', 'red',\n",
       "       'rising', 'river', 'road', 'rock', 'rose', 'saga', 'scarpetta',\n",
       "       'school', 'science', 'sea', 'second', 'secret', 'secrets',\n",
       "       'series', 'set', 'seven', 'shadow', 'shadows', 'short', 'sisters',\n",
       "       'small', 'snow', 'son', 'song', 'soul', 'star', 'stars',\n",
       "       'stephanie', 'stephanie plum', 'stone', 'stories', 'storm',\n",
       "       'story', 'strange', 'street', 'summer', 'sun', 'sword', 'tale',\n",
       "       'tales', 'tell', 'things', 'time', 'tree', 'trilogy', 'true',\n",
       "       'true story', 'truth', 'twilight', 'universe', 'vampire',\n",
       "       'vampire hunter', 'vampires', 'vol', 'volume', 'walking',\n",
       "       'walking dead', 'war', 'wars', 'water', 'way', 'wheel', 'white',\n",
       "       'wicked', 'wife', 'wild', 'winter', 'witch', 'woman', 'women',\n",
       "       'world', 'year', 'years'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본에는 \n",
    "# vect.get_feature_names() 사용\n",
    "# 1.0 버전 부터 get_feature_names_out() 로 대체\n",
    "features = vect.get_feature_names_out()\n",
    "\n",
    "# 261개의 단어들 확인\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity between Titles\n",
    "Things to do:\n",
    "\n",
    "* Initialize Cosine similarity into title matrix\n",
    "* Extract features from book title\n",
    "* Using Cosine similarity between this title and all other titles to be recommended the top 10 books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 단어 문서 행렬로 코사인 유사도 계산\n",
    "# 자기 자신을 포함한 10,000개의 문서 벡터 간의 유사도를 기록한 행렬\n",
    "# 모든 10,000개 책 제목의 상호 유사도\n",
    "cosine_sim_titles = cosine_similarity(title_matrix, title_matrix)\n",
    "cosine_sim_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me Talk Pretty One Day'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100번 째 행 책의 제목\n",
    "title_id = 100\n",
    "books_title['title'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 261)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(title_matrix[title_id].toarray().shape)\n",
    "title_matrix[title_id].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.squeeze\n",
    "# axis가 1인 축을 제거\n",
    "feature_array = np.squeeze(title_matrix[title_id].toarray())\n",
    "print(feature_array.shape)\n",
    "feature_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 63, 179]),)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값이 0보다 큰 값 추출\n",
    "# 261개의 단어 중 등장한 단어의 index\n",
    "# 튜플로 출력된 모습\n",
    "idx = np.where(feature_array > 0)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day', 'pretty']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 책 제목 : Me Talk Pretty One Day\n",
    "# Me, Talk, One 은 단어장에 없는 듯\n",
    "[features[x] for x in idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63, 179])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find index of feature\n",
    "idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n",
       "       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n",
       "       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추천할 책의 수\n",
    "n = 15\n",
    "\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id, ]), axis=0)[0:n]\n",
    "top_n_sim_values = cosine_sim_titles[title_id, top_n_idx]\n",
    "top_n_sim_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바로 위 뜯어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title_id = 100\n",
    "# 100번 째 행 데이터 추출\n",
    "cosine_sim_titles[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# 두 개가 같음\n",
    "print(sum(cosine_sim_titles[title_id, ] == cosine_sim_titles[title_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 6650, 6651, ...,  988, 3729,  100])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정렬(오름차순) 후 인덱스 반환\n",
    "# 자기 자신, 100이 가장 높은 것 확인\n",
    "np.argsort(cosine_sim_titles[title_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100, 3729,  988,  836, 2348, 3311, 6804, 6886, 5765,  783, 9210,\n",
       "       9703, 9637, 7330, 7707])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코사인 유사도 높은 것을 추천해야 하므로 flip\n",
    "# 추천하고 싶은 개수만큼 슬라이싱\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id, ]), axis=0)[0:15]\n",
    "top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n",
       "       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n",
       "       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코사인 유사도가 높은 인덱스에 해당하는 데이터 추출\n",
    "top_n_sim_values = cosine_sim_titles[title_id, top_n_idx]\n",
    "top_n_sim_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다시 돌아와서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 100 3729  988  836 2348 3311 6804 6886 5765  783 9210 9703 9637 7330\n",
      " 7707]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100                                Me Talk Pretty One Day\n",
       "3729                                            Labor Day\n",
       "988                                 The Day of the Jackal\n",
       "836                             Every Day (Every Day, #1)\n",
       "2348    No Easy Day: The Firsthand Account of the Miss...\n",
       "3311                                          Pretty Baby\n",
       "6804                     Graduation Day (The Testing, #3)\n",
       "6886                                 Day Watch (Watch #2)\n",
       "5765                          The Given Day (Coughlin #1)\n",
       "783                                      For One More Day\n",
       "9210             Beyond Exile (Day by Day Armageddon,# 2)\n",
       "9703    The Pretty Committee Strikes Back (The Clique,...\n",
       "9637                                 Day 21 (The 100, #2)\n",
       "7330                                      Pretty in Plaid\n",
       "7707                            A Grown-Up Kind of Pretty\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코사인 유사도 TOPn 중 0보다 큰 애들만 추출\n",
    "top_n_idx = top_n_idx[top_n_sim_values > 0]\n",
    "print(top_n_idx)\n",
    "\n",
    "# 인덱스에 해당하는 책 제목 추출\n",
    "books_title['title'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금까지의 과정 한번에 처리하는 함수\n",
    "def return_sim_books(title_id, title_matrix, vectorizer, top_n = 10):\n",
    "    \n",
    "    # 코사인 유사도 행렬 생성\n",
    "    sim_matrix = cosine_similarity(title_matrix, title_matrix)\n",
    "\n",
    "    # 단어들\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "\n",
    "    top_n_idx = np.flip(np.argsort(sim_matrix[title_id, ]), axis=0)[0:top_n]\n",
    "    top_n_sim_values = sim_matrix[title_id, top_n_idx]\n",
    "    \n",
    "    top_n_idx = top_n_idx[top_n_sim_values > 0]\n",
    "    scores = top_n_sim_values[top_n_sim_values > 0]\n",
    "    \n",
    "    sim_books_idx = books_title['title'].iloc[top_n_idx].index\n",
    "    words = []\n",
    "    for book_idx in sim_books_idx:\n",
    "        try:\n",
    "            feature_array = np.squeeze(title_matrix[book_idx,].toarray())\n",
    "        except:\n",
    "            feature_array = np.squeeze(title_matrix[book_idx,])\n",
    "        idx = np.where(feature_array > 0)\n",
    "        words.append([\" , \".join([features[i] for i in idx[0]])])\n",
    "        \n",
    "    res = pd.DataFrame({\"book_title\" : books_title['title'].iloc[title_id],\n",
    "           \"sim_books\": books_title['title'].iloc[top_n_idx].values, \"words\":words,\n",
    "           \"scores\":scores}, columns = [\"book_title\",\"sim_books\",\"scores\",\"words\"])\n",
    "    \n",
    "    \n",
    "    # return sim_matrix[title_id]\n",
    "    # return np.argsort(sim_matrix[title_id])\n",
    "    # return np.flip(np.argsort(sim_matrix[title_id, ]), axis=0)[0:top_n]\n",
    "    return top_n_idx\n",
    "    # return top_n_sim_values\n",
    "    # return sim_books_idx\n",
    "    # return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me Talk Pretty One Day\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer='word',ngram_range=(1,2),stop_words='english', min_df = 0.001)\n",
    "vect.fit(books_title['title'])\n",
    "title_mat = vect.transform(books_title['title'])\n",
    "print(books_title['title'][100])\n",
    "return_sim_books(10,title_matrix,vect,top_n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CountVectorizer we could extract text from book titles and recommend similar titles. <br>\n",
    "A limitation I came across was for titles like \"The Kite Runner\" & \"The Dinner\". <br>\n",
    "It was unable to recommend similar books because of the rare words like kite and dinner in the dataset <br>\n",
    "so we have to look at other better ways for recommendations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(books_title['title'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "The Hunger Games (The Hunger Games, #1)                                                         0\n",
       "Harry Potter and the Sorcerer's Stone (Harry Potter, #1)                                        1\n",
       "Twilight (Twilight, #1)                                                                         2\n",
       "To Kill a Mockingbird                                                                           3\n",
       "The Great Gatsby                                                                                4\n",
       "                                                                                             ... \n",
       "Bayou Moon (The Edge, #2)                                                                    9995\n",
       "Means of Ascent (The Years of Lyndon Johnson, #2)                                            9996\n",
       "The Mauritius Command                                                                        9997\n",
       "Cinderella Ate My Daughter: Dispatches from the Frontlines of the New Girlie-Girl Culture    9998\n",
       "The First World War                                                                          9999\n",
       "Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = books_title['title']\n",
    "indices = pd.Series(books_title.index, index=books_title['title'])\n",
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_recommendations(title, n):\n",
    "    # 기준이 되는 책 제목의 index\n",
    "    idx = indices[title]\n",
    "\n",
    "    # [(idx, 유사도), (idx, 유사도), (idx, 유사도)]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # 유사도 기준 내림차순 정렬\n",
    "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    # 나 자신을 제외하고 다음 순서부터 n개의 유사도 추출\n",
    "    sim_scores = sim_scores[1:n+1]\n",
    "\n",
    "    # 유사도의 index를 활용하여 유사도가 높은 책 제목의 index 추출\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # index로 책 제목 반환\n",
    "    return titles.iloc[book_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kite Runner\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8946                                        Once a Runner\n",
       "90                      The Maze Runner (Maze Runner, #1)\n",
       "375                      The Death Cure (Maze Runner, #3)\n",
       "945                    The Kill Order (Maze Runner, #0.5)\n",
       "258                   The Scorch Trials (Maze Runner, #2)\n",
       "6711    Ultramarathon Man: Confessions of an All-Night...\n",
       "0                 The Hunger Games (The Hunger Games, #1)\n",
       "1       Harry Potter and the Sorcerer's Stone (Harry P...\n",
       "2                                 Twilight (Twilight, #1)\n",
       "3                                   To Kill a Mockingbird\n",
       "4                                        The Great Gatsby\n",
       "5                                  The Fault in Our Stars\n",
       "6                                              The Hobbit\n",
       "7                                  The Catcher in the Rye\n",
       "8                   Angels & Demons  (Robert Langdon, #1)\n",
       "9                                     Pride and Prejudice\n",
       "11                              Divergent (Divergent, #1)\n",
       "12                                                   1984\n",
       "13                                            Animal Farm\n",
       "14                              The Diary of a Young Girl\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recommend n books for a book having index 1\n",
    "book_index = 10\n",
    "n = 20\n",
    "\n",
    "print(books_title['title'][book_index])\n",
    "book_recommendations(books_title.title[book_index],n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend similar books based on a list of books read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5871    A Tale of Two Cities / Great Expectations\n",
       "2697                             Invisible Cities\n",
       "1699                    A Tale for the Time Being\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_recommendations('A Tale of Two Cities', 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n",
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3, 1, 2])\n",
    "print(np.argsort(x))\n",
    "print(np.argsort(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   3],\n",
       "       [  3,   2],\n",
       "       [  1, 100]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0, 3], [3, 2], [1, 100]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b37592e24976bbc2b4793f9e16cde29a149096caf81a3ecbdead9daa6a7261c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
